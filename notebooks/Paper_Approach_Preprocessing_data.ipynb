{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths to the directories containing your modules\n",
    "src_path_1 = r'C:\\Users\\mokht\\Desktop\\GAN-Drug-Generator\\my_implementations\\src'\n",
    "src_path_2 = r'C:\\Users\\mokht\\Desktop\\GAN-Drug-Generator\\src'\n",
    "\n",
    "# Append paths to sys.path if they are not already included\n",
    "for path in [src_path_1, src_path_2]:\n",
    "    if path not in sys.path:\n",
    "        sys.path.append(path)\n",
    "\n",
    "# Now import your modules\n",
    "from Vocabulary2 import Vocabulary\n",
    "from Autoencoder2_emb import Autoencoder as AE\n",
    "from utils import *\n",
    "from my_WGAN_GP import WGAN_GP,  Generator\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cc1cc(NC(=O)COC(=O)COc2ccc3c4c(c(=O)oc3c2)CCC4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cn1c2c([N+](=O)[O-])cccc2c(=O)c2c(O)cc3c(c21)C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C=C[C@]1(C)CC[C@H]2C(=C[C@@H]3OC(=O)[C@]4(C)[C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COc1cc(CC[C@H](C[C@@H](OC(C)=O)[C@@H]2CCCCC[C@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cn1ccoc1=Nc1ccc(Cl)c(Cl)c1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              SMILES\n",
       "0  Cc1cc(NC(=O)COC(=O)COc2ccc3c4c(c(=O)oc3c2)CCC4...\n",
       "1  Cn1c2c([N+](=O)[O-])cccc2c(=O)c2c(O)cc3c(c21)C...\n",
       "2  C=C[C@]1(C)CC[C@H]2C(=C[C@@H]3OC(=O)[C@]4(C)[C...\n",
       "3  COc1cc(CC[C@H](C[C@@H](OC(C)=O)[C@@H]2CCCCC[C@...\n",
       "4                         Cn1ccoc1=Nc1ccc(Cl)c(Cl)c1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_vae_train = r'C:\\Users\\mokht\\Desktop\\GAN-DRUG-GENERATOR\\my_implementations\\data\\clean_smiles.csv'\n",
    "df_vae_train = pd.read_csv(file_path_vae_train)\n",
    "df_vae_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['G', 'C', '=', 'C', '[', 'C', '@', ']', '1', '(', 'C', ')', 'C', 'C', '[', 'C', '@', 'H', ']', '2', 'C', '(', '=', 'C', '[', 'C', '@', '@', 'H', ']', '3', 'O', 'C', '(', '=', 'O', ')', '[', 'C', '@', ']', '4', '(', 'C', ')', '[', 'C', '@', 'H', ']', '3', '[', 'C', '@', ']', '2', '3', 'C', 'C', '[', 'C', '@', '@', ']', '4', '(', 'O', ')', 'O', 'C', '3', ')', 'C', '1', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "[26, 23, 19, 23, 36, 23, 20, 38, 10, 2, 23, 3, 23, 23, 36, 23, 20, 27, 38, 11, 23, 2, 19, 23, 36, 23, 20, 20, 27, 38, 12, 31, 23, 2, 19, 31, 3, 36, 23, 20, 38, 13, 2, 23, 3, 36, 23, 20, 27, 38, 12, 36, 23, 20, 38, 11, 12, 23, 23, 36, 23, 20, 20, 38, 13, 2, 31, 3, 31, 23, 12, 3, 23, 10, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21]\n"
     ]
    }
   ],
   "source": [
    "smiles = df_vae_train['SMILES'].tolist()\n",
    "\n",
    "# Create and prepare Vocabulary object\n",
    "vocab = Vocabulary(r'C:\\Users\\mokht\\Desktop\\GAN-Drug-Generator\\src\\Vocab_complete.txt', max_len=100)\n",
    "tok, _ = vocab.tokenize(smiles)  \n",
    "print(tok[2])\n",
    "X_train = vocab.encode(tok)\n",
    "print(X_train[2])\n",
    "len_X_train = len(X_train)\n",
    "X_train = np.reshape(X_train, (len_X_train, vocab.max_len, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <keras.engine.functional.Functional object at 0x000001DCA158D940>>\n",
      "Model: \"Autoencoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " smiles_to_latent_model (Functi  (None, 256)         3172864     ['encoder_inputs[0][0]']         \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, 100, 45)]    0           []                               \n",
      "                                                                                                  \n",
      " latent_to_states_model (Functi  [(None, 512),       534528      ['smiles_to_latent_model[0][0]'] \n",
      " onal)                           (None, 512),                                                     \n",
      "                                 (None, 512),                                                     \n",
      "                                 (None, 512)]                                                     \n",
      "                                                                                                  \n",
      " states_to_smiles_model (Functi  (None, 100, 45)     3269165     ['decoder_inputs[0][0]',         \n",
      " onal)                                                            'latent_to_states_model[0][0]', \n",
      "                                                                  'latent_to_states_model[0][1]', \n",
      "                                                                  'latent_to_states_model[0][2]', \n",
      "                                                                  'latent_to_states_model[0][3]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,976,557\n",
      "Trainable params: 6,964,781\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder setup and loading\n",
    "path_model = r'C:\\Users\\mokht\\Desktop\\GAN-Drug-Generator\\models\\AE\\Exp9model2256_500000_biLSTM2_units512_dec_layers2-128-0.9-adam-0.1-256'\n",
    "latent_dim = 256\n",
    "lstm_units = 512\n",
    "batch_norm = True\n",
    "batch_norm_momentum = 0.9\n",
    "noise_std = 0.1\n",
    "numb_dec_layer = 2\n",
    "emb_dim = 256\n",
    "decoder_input_shape = (vocab.max_len, vocab.vocab_size)\n",
    "output_dim = vocab.vocab_size\n",
    "autoencoder = AE(path_model, decoder_input_shape, latent_dim, lstm_units, output_dim, batch_norm, batch_norm_momentum, noise_std, numb_dec_layer, emb_dim, vocab.vocab_size, vocab.max_len)\n",
    "autoencoder.load_autoencoder_model(f'{path_model}\\\\model--86--0.0013.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use autoencoder to transform data\n",
    "x_latent = autoencoder.smiles_to_latent_model.predict(X_train)\n",
    "\n",
    "# Optionally, check the shape and some entries of the latent vectors\n",
    "print(\"Shape of the latent vectors:\", x_latent.shape)\n",
    "print(\"Example latent vectors:\", x_latent[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_latent = pd.DataFrame(x_latent)\n",
    "df_latent.to_csv(\"x_latent.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.531973</td>\n",
       "      <td>-3.658263</td>\n",
       "      <td>-5.780501</td>\n",
       "      <td>0.985559</td>\n",
       "      <td>-2.344686</td>\n",
       "      <td>-0.395197</td>\n",
       "      <td>-4.155104</td>\n",
       "      <td>-6.309148</td>\n",
       "      <td>-4.828435</td>\n",
       "      <td>0.702009</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.739101</td>\n",
       "      <td>0.326534</td>\n",
       "      <td>-3.071619</td>\n",
       "      <td>-3.134870</td>\n",
       "      <td>-15.127769</td>\n",
       "      <td>1.245177</td>\n",
       "      <td>-1.771754</td>\n",
       "      <td>2.426990</td>\n",
       "      <td>-0.225869</td>\n",
       "      <td>-6.589633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.775347</td>\n",
       "      <td>-3.148699</td>\n",
       "      <td>-6.248262</td>\n",
       "      <td>1.709087</td>\n",
       "      <td>-4.530838</td>\n",
       "      <td>3.879724</td>\n",
       "      <td>-0.770210</td>\n",
       "      <td>-3.908162</td>\n",
       "      <td>2.016663</td>\n",
       "      <td>1.492469</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.231998</td>\n",
       "      <td>-0.959295</td>\n",
       "      <td>-3.773522</td>\n",
       "      <td>-4.095211</td>\n",
       "      <td>-15.127769</td>\n",
       "      <td>0.430275</td>\n",
       "      <td>-1.822708</td>\n",
       "      <td>-2.700474</td>\n",
       "      <td>0.659260</td>\n",
       "      <td>-7.375647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.627451</td>\n",
       "      <td>-2.064672</td>\n",
       "      <td>-4.804461</td>\n",
       "      <td>0.738892</td>\n",
       "      <td>0.306322</td>\n",
       "      <td>-5.283590</td>\n",
       "      <td>3.891021</td>\n",
       "      <td>-3.702524</td>\n",
       "      <td>-1.636688</td>\n",
       "      <td>-0.615832</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.305829</td>\n",
       "      <td>-1.628287</td>\n",
       "      <td>-4.945182</td>\n",
       "      <td>-1.267771</td>\n",
       "      <td>-15.127769</td>\n",
       "      <td>1.086514</td>\n",
       "      <td>-0.967919</td>\n",
       "      <td>1.820961</td>\n",
       "      <td>-3.429222</td>\n",
       "      <td>-4.226261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.685610</td>\n",
       "      <td>0.986622</td>\n",
       "      <td>-3.091686</td>\n",
       "      <td>2.099416</td>\n",
       "      <td>-0.112864</td>\n",
       "      <td>1.783210</td>\n",
       "      <td>-2.707843</td>\n",
       "      <td>-6.750401</td>\n",
       "      <td>0.359075</td>\n",
       "      <td>0.536423</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.824604</td>\n",
       "      <td>1.153023</td>\n",
       "      <td>-1.124250</td>\n",
       "      <td>-1.086287</td>\n",
       "      <td>-15.127769</td>\n",
       "      <td>3.835603</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>-0.827079</td>\n",
       "      <td>-0.880800</td>\n",
       "      <td>-0.114948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.393992</td>\n",
       "      <td>0.128058</td>\n",
       "      <td>-1.699092</td>\n",
       "      <td>0.500346</td>\n",
       "      <td>-0.277808</td>\n",
       "      <td>0.043082</td>\n",
       "      <td>-3.638350</td>\n",
       "      <td>-1.160822</td>\n",
       "      <td>0.586198</td>\n",
       "      <td>0.949871</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.559831</td>\n",
       "      <td>-2.123939</td>\n",
       "      <td>-6.052945</td>\n",
       "      <td>-3.338126</td>\n",
       "      <td>-15.127769</td>\n",
       "      <td>1.170421</td>\n",
       "      <td>-0.906683</td>\n",
       "      <td>-0.605919</td>\n",
       "      <td>0.411519</td>\n",
       "      <td>-1.454076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 256 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  1.531973 -3.658263 -5.780501  0.985559 -2.344686 -0.395197 -4.155104   \n",
       "1 -3.775347 -3.148699 -6.248262  1.709087 -4.530838  3.879724 -0.770210   \n",
       "2  1.627451 -2.064672 -4.804461  0.738892  0.306322 -5.283590  3.891021   \n",
       "3 -6.685610  0.986622 -3.091686  2.099416 -0.112864  1.783210 -2.707843   \n",
       "4 -4.393992  0.128058 -1.699092  0.500346 -0.277808  0.043082 -3.638350   \n",
       "\n",
       "        7         8         9    ...       246       247       248       249  \\\n",
       "0 -6.309148 -4.828435  0.702009  ... -2.739101  0.326534 -3.071619 -3.134870   \n",
       "1 -3.908162  2.016663  1.492469  ... -4.231998 -0.959295 -3.773522 -4.095211   \n",
       "2 -3.702524 -1.636688 -0.615832  ... -5.305829 -1.628287 -4.945182 -1.267771   \n",
       "3 -6.750401  0.359075  0.536423  ... -4.824604  1.153023 -1.124250 -1.086287   \n",
       "4 -1.160822  0.586198  0.949871  ... -3.559831 -2.123939 -6.052945 -3.338126   \n",
       "\n",
       "         250       251       252       253       254       255  \n",
       "0 -15.127769  1.245177 -1.771754  2.426990 -0.225869 -6.589633  \n",
       "1 -15.127769  0.430275 -1.822708 -2.700474  0.659260 -7.375647  \n",
       "2 -15.127769  1.086514 -0.967919  1.820961 -3.429222 -4.226261  \n",
       "3 -15.127769  3.835603  0.000484 -0.827079 -0.880800 -0.114948  \n",
       "4 -15.127769  1.170421 -0.906683 -0.605919  0.411519 -1.454076  \n",
       "\n",
       "[5 rows x 256 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_latent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300:   0%|          | 0/1561 [00:00<?, ?it/s]c:\\Users\\mokht\\anaconda3\\envs\\myenv\\lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\cuda\\CublasHandlePool.cpp:135.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Epoch 1/300: 100%|██████████| 1561/1561 [00:26<00:00, 59.92it/s, D_loss=-132, G_loss=-4.16]\n",
      "Epoch 2/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.61it/s, D_loss=-134, G_loss=-7.69]\n",
      "Epoch 3/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.12it/s, D_loss=-129, G_loss=-10.3]\n",
      "Epoch 4/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.75it/s, D_loss=-134, G_loss=-13.3]\n",
      "Epoch 5/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.47it/s, D_loss=-142, G_loss=-14.7]\n",
      "Epoch 6/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.06it/s, D_loss=-131, G_loss=-18.3]\n",
      "Epoch 7/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.28it/s, D_loss=-124, G_loss=-18.7]\n",
      "Epoch 8/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.44it/s, D_loss=-142, G_loss=-19.5]\n",
      "Epoch 9/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.22it/s, D_loss=-127, G_loss=-19.1]\n",
      "Epoch 10/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.60it/s, D_loss=-117, G_loss=-18.5]\n",
      "Epoch 11/300: 100%|██████████| 1561/1561 [00:23<00:00, 66.22it/s, D_loss=-128, G_loss=-20]  \n",
      "Epoch 12/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.07it/s, D_loss=-128, G_loss=-19.2]\n",
      "Epoch 13/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.24it/s, D_loss=-120, G_loss=-20.2]\n",
      "Epoch 14/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.27it/s, D_loss=-131, G_loss=-20]  \n",
      "Epoch 15/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.18it/s, D_loss=-138, G_loss=-20.5]\n",
      "Epoch 16/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.36it/s, D_loss=-126, G_loss=-22.6]\n",
      "Epoch 17/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.45it/s, D_loss=-126, G_loss=-25.5]\n",
      "Epoch 18/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.60it/s, D_loss=-124, G_loss=-27.3]\n",
      "Epoch 19/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.50it/s, D_loss=-128, G_loss=-27.3]\n",
      "Epoch 20/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.90it/s, D_loss=-132, G_loss=-26.8]\n",
      "Epoch 21/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.07it/s, D_loss=-127, G_loss=-27.4]\n",
      "Epoch 22/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.12it/s, D_loss=-117, G_loss=-27.3]\n",
      "Epoch 23/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.18it/s, D_loss=-122, G_loss=-28.6]\n",
      "Epoch 24/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.69it/s, D_loss=-114, G_loss=-26.1]\n",
      "Epoch 25/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.58it/s, D_loss=-122, G_loss=-27.6]\n",
      "Epoch 26/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.90it/s, D_loss=-129, G_loss=-27.2]\n",
      "Epoch 27/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.08it/s, D_loss=-123, G_loss=-27.2]\n",
      "Epoch 28/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.28it/s, D_loss=-122, G_loss=-28]  \n",
      "Epoch 29/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.28it/s, D_loss=-119, G_loss=-27]  \n",
      "Epoch 30/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.17it/s, D_loss=-126, G_loss=-27.9]\n",
      "Epoch 31/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.58it/s, D_loss=-119, G_loss=-27]  \n",
      "Epoch 32/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.41it/s, D_loss=-124, G_loss=-27.8]\n",
      "Epoch 33/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.34it/s, D_loss=-131, G_loss=-27.2]\n",
      "Epoch 34/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.04it/s, D_loss=-121, G_loss=-27.5]\n",
      "Epoch 35/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.00it/s, D_loss=-114, G_loss=-26.9]\n",
      "Epoch 36/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.18it/s, D_loss=-126, G_loss=-28.8]\n",
      "Epoch 37/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.69it/s, D_loss=-121, G_loss=-30.4]\n",
      "Epoch 38/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.28it/s, D_loss=-126, G_loss=-29.2]\n",
      "Epoch 39/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.52it/s, D_loss=-115, G_loss=-29.1]\n",
      "Epoch 40/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.79it/s, D_loss=-119, G_loss=-29.1]\n",
      "Epoch 41/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.16it/s, D_loss=-114, G_loss=-29] \n",
      "Epoch 42/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.61it/s, D_loss=-111, G_loss=-29.4]\n",
      "Epoch 43/300: 100%|██████████| 1561/1561 [00:24<00:00, 64.15it/s, D_loss=-120, G_loss=-28.8]\n",
      "Epoch 44/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.70it/s, D_loss=-114, G_loss=-29.1]\n",
      "Epoch 45/300: 100%|██████████| 1561/1561 [00:24<00:00, 64.34it/s, D_loss=-108, G_loss=-30.4]\n",
      "Epoch 46/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.51it/s, D_loss=-116, G_loss=-29.5]\n",
      "Epoch 47/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.01it/s, D_loss=-123, G_loss=-29.5]\n",
      "Epoch 48/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.34it/s, D_loss=-111, G_loss=-30]  \n",
      "Epoch 49/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.73it/s, D_loss=-117, G_loss=-29.1]\n",
      "Epoch 50/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.35it/s, D_loss=-110, G_loss=-30.4]\n",
      "Epoch 51/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.74it/s, D_loss=-118, G_loss=-30.5]\n",
      "Epoch 52/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.71it/s, D_loss=-117, G_loss=-30.2]\n",
      "Epoch 53/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.93it/s, D_loss=-114, G_loss=-29.4]\n",
      "Epoch 54/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.94it/s, D_loss=-109, G_loss=-29.8]\n",
      "Epoch 55/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.45it/s, D_loss=-115, G_loss=-28.1]\n",
      "Epoch 56/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.20it/s, D_loss=-114, G_loss=-32]  \n",
      "Epoch 57/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.18it/s, D_loss=-113, G_loss=-30.5]\n",
      "Epoch 58/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.97it/s, D_loss=-112, G_loss=-30.7]\n",
      "Epoch 59/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.80it/s, D_loss=-106, G_loss=-30.9]\n",
      "Epoch 60/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.17it/s, D_loss=-122, G_loss=-32.3]\n",
      "Epoch 61/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.79it/s, D_loss=-106, G_loss=-29.6]\n",
      "Epoch 62/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.57it/s, D_loss=-108, G_loss=-31.4]\n",
      "Epoch 63/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.17it/s, D_loss=-105, G_loss=-31]  \n",
      "Epoch 64/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.31it/s, D_loss=-101, G_loss=-33.1]\n",
      "Epoch 65/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.20it/s, D_loss=-114, G_loss=-31.8]\n",
      "Epoch 66/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.69it/s, D_loss=-117, G_loss=-30.6]\n",
      "Epoch 67/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.60it/s, D_loss=-113, G_loss=-31.8]\n",
      "Epoch 68/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.96it/s, D_loss=-112, G_loss=-31.7]\n",
      "Epoch 69/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.71it/s, D_loss=-100, G_loss=-30.3]\n",
      "Epoch 70/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.95it/s, D_loss=-115, G_loss=-31.6]\n",
      "Epoch 71/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.93it/s, D_loss=-108, G_loss=-32]  \n",
      "Epoch 72/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.62it/s, D_loss=-116, G_loss=-32.8]\n",
      "Epoch 73/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.90it/s, D_loss=-106, G_loss=-32.6]\n",
      "Epoch 74/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.43it/s, D_loss=-108, G_loss=-32.1]\n",
      "Epoch 75/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.60it/s, D_loss=-111, G_loss=-32.7]\n",
      "Epoch 76/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.16it/s, D_loss=-109, G_loss=-33.3]\n",
      "Epoch 77/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.87it/s, D_loss=-105, G_loss=-32.1]\n",
      "Epoch 78/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.97it/s, D_loss=-111, G_loss=-32.2]\n",
      "Epoch 79/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.76it/s, D_loss=-103, G_loss=-33.6]\n",
      "Epoch 80/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.40it/s, D_loss=-109, G_loss=-32.2]\n",
      "Epoch 81/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.79it/s, D_loss=-107, G_loss=-32.2]\n",
      "Epoch 82/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.49it/s, D_loss=-106, G_loss=-31]  \n",
      "Epoch 83/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.42it/s, D_loss=-98.9, G_loss=-31.5]\n",
      "Epoch 84/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.53it/s, D_loss=-97.9, G_loss=-32.1]\n",
      "Epoch 85/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.80it/s, D_loss=-99.2, G_loss=-33] \n",
      "Epoch 86/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.94it/s, D_loss=-106, G_loss=-33.6]\n",
      "Epoch 87/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.35it/s, D_loss=-100, G_loss=-31.4]\n",
      "Epoch 88/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.72it/s, D_loss=-101, G_loss=-32.6]\n",
      "Epoch 89/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.56it/s, D_loss=-108, G_loss=-32]   \n",
      "Epoch 90/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.03it/s, D_loss=-103, G_loss=-32.3]\n",
      "Epoch 91/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.41it/s, D_loss=-110, G_loss=-33.4]\n",
      "Epoch 92/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.57it/s, D_loss=-102, G_loss=-34.1] \n",
      "Epoch 93/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.93it/s, D_loss=-103, G_loss=-31.5]\n",
      "Epoch 94/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.11it/s, D_loss=-90.4, G_loss=-33.3]\n",
      "Epoch 95/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.31it/s, D_loss=-96.3, G_loss=-34.1]\n",
      "Epoch 96/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.26it/s, D_loss=-99.1, G_loss=-33.7]\n",
      "Epoch 97/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.02it/s, D_loss=-104, G_loss=-33.3]\n",
      "Epoch 98/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.16it/s, D_loss=-99.6, G_loss=-33.4]\n",
      "Epoch 99/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.41it/s, D_loss=-103, G_loss=-32.9] \n",
      "Epoch 100/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.36it/s, D_loss=-102, G_loss=-32.7]\n",
      "Epoch 101/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.88it/s, D_loss=-91, G_loss=-33]   \n",
      "Epoch 102/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.09it/s, D_loss=-102, G_loss=-33.5] \n",
      "Epoch 103/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.83it/s, D_loss=-96.3, G_loss=-32.3]\n",
      "Epoch 104/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.08it/s, D_loss=-93.1, G_loss=-34.2]\n",
      "Epoch 105/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.20it/s, D_loss=-102, G_loss=-32.5] \n",
      "Epoch 106/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.36it/s, D_loss=-95.7, G_loss=-33.5]\n",
      "Epoch 107/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.16it/s, D_loss=-84.4, G_loss=-33.7]\n",
      "Epoch 108/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.37it/s, D_loss=-98, G_loss=-34]    \n",
      "Epoch 109/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.59it/s, D_loss=-101, G_loss=-35.6] \n",
      "Epoch 110/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.83it/s, D_loss=-100, G_loss=-33.8] \n",
      "Epoch 111/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.89it/s, D_loss=-98.1, G_loss=-33.8]\n",
      "Epoch 112/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.22it/s, D_loss=-94.5, G_loss=-33.4]\n",
      "Epoch 113/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.32it/s, D_loss=-90.6, G_loss=-34.5]\n",
      "Epoch 114/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.78it/s, D_loss=-95.4, G_loss=-35.7]\n",
      "Epoch 115/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.24it/s, D_loss=-97.7, G_loss=-34.5]\n",
      "Epoch 116/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.49it/s, D_loss=-97.1, G_loss=-34.1]\n",
      "Epoch 117/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.44it/s, D_loss=-92.2, G_loss=-34.1]\n",
      "Epoch 118/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.41it/s, D_loss=-99.8, G_loss=-35.6]\n",
      "Epoch 119/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.91it/s, D_loss=-101, G_loss=-36]   \n",
      "Epoch 120/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.38it/s, D_loss=-85.7, G_loss=-35.3]\n",
      "Epoch 121/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.97it/s, D_loss=-98.5, G_loss=-35.2]\n",
      "Epoch 122/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.11it/s, D_loss=-91.3, G_loss=-35.8]\n",
      "Epoch 123/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.54it/s, D_loss=-98.2, G_loss=-33.4]\n",
      "Epoch 124/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.29it/s, D_loss=-95, G_loss=-35.3]  \n",
      "Epoch 125/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.89it/s, D_loss=-90.8, G_loss=-36.3]\n",
      "Epoch 126/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.32it/s, D_loss=-99.2, G_loss=-34.7]\n",
      "Epoch 127/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.97it/s, D_loss=-94.5, G_loss=-36.3]\n",
      "Epoch 128/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.87it/s, D_loss=-89.3, G_loss=-35.5]\n",
      "Epoch 129/300: 100%|██████████| 1561/1561 [00:24<00:00, 64.01it/s, D_loss=-100, G_loss=-36.8] \n",
      "Epoch 130/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.65it/s, D_loss=-95.3, G_loss=-36.4]\n",
      "Epoch 131/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.86it/s, D_loss=-97, G_loss=-36]    \n",
      "Epoch 132/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.75it/s, D_loss=-92.7, G_loss=-36.4]\n",
      "Epoch 133/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.26it/s, D_loss=-94.7, G_loss=-35.2]\n",
      "Epoch 134/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.84it/s, D_loss=-88.2, G_loss=-38.1]\n",
      "Epoch 135/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.99it/s, D_loss=-94.2, G_loss=-36.3]\n",
      "Epoch 136/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.57it/s, D_loss=-89.8, G_loss=-34] \n",
      "Epoch 137/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.67it/s, D_loss=-86.4, G_loss=-34.6]\n",
      "Epoch 138/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.88it/s, D_loss=-90.5, G_loss=-35.8]\n",
      "Epoch 139/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.27it/s, D_loss=-90.7, G_loss=-36.4]\n",
      "Epoch 140/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.18it/s, D_loss=-89.2, G_loss=-36.2]\n",
      "Epoch 141/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.85it/s, D_loss=-97.8, G_loss=-34.8]\n",
      "Epoch 142/300: 100%|██████████| 1561/1561 [00:24<00:00, 64.59it/s, D_loss=-87.3, G_loss=-37.1]\n",
      "Epoch 143/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.67it/s, D_loss=-85.1, G_loss=-35.5]\n",
      "Epoch 144/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.02it/s, D_loss=-94.6, G_loss=-34.9]\n",
      "Epoch 145/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.28it/s, D_loss=-86.6, G_loss=-36.2]\n",
      "Epoch 146/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.71it/s, D_loss=-93.2, G_loss=-36.8]\n",
      "Epoch 147/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.17it/s, D_loss=-96.8, G_loss=-36.1]\n",
      "Epoch 148/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.08it/s, D_loss=-91.6, G_loss=-36.9]\n",
      "Epoch 149/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.58it/s, D_loss=-96, G_loss=-35.4]  \n",
      "Epoch 150/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.45it/s, D_loss=-86.1, G_loss=-37.2]\n",
      "Epoch 151/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.90it/s, D_loss=-92.7, G_loss=-35.5]\n",
      "Epoch 152/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.01it/s, D_loss=-94.7, G_loss=-36.2]\n",
      "Epoch 153/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.65it/s, D_loss=-89.8, G_loss=-37.6]\n",
      "Epoch 154/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.85it/s, D_loss=-88.5, G_loss=-39.3]\n",
      "Epoch 155/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.96it/s, D_loss=-91.3, G_loss=-37]  \n",
      "Epoch 156/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.40it/s, D_loss=-86.2, G_loss=-37]  \n",
      "Epoch 157/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.97it/s, D_loss=-88.5, G_loss=-38]  \n",
      "Epoch 158/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.56it/s, D_loss=-88.4, G_loss=-38.7]\n",
      "Epoch 159/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.61it/s, D_loss=-98.9, G_loss=-36.8]\n",
      "Epoch 160/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.37it/s, D_loss=-87.2, G_loss=-37.8]\n",
      "Epoch 161/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.57it/s, D_loss=-89.6, G_loss=-37.9]\n",
      "Epoch 162/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.28it/s, D_loss=-89.2, G_loss=-36.1]\n",
      "Epoch 163/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.41it/s, D_loss=-92.4, G_loss=-38.6]\n",
      "Epoch 164/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.44it/s, D_loss=-93.2, G_loss=-36.1]\n",
      "Epoch 165/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.57it/s, D_loss=-83.5, G_loss=-36.9]\n",
      "Epoch 166/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.54it/s, D_loss=-82.8, G_loss=-37.5]\n",
      "Epoch 167/300: 100%|██████████| 1561/1561 [00:26<00:00, 59.65it/s, D_loss=-86.7, G_loss=-38.4]\n",
      "Epoch 168/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.04it/s, D_loss=-83.6, G_loss=-36.4]\n",
      "Epoch 169/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.48it/s, D_loss=-90.2, G_loss=-39.2]\n",
      "Epoch 170/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.65it/s, D_loss=-81.3, G_loss=-39.3]\n",
      "Epoch 171/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.04it/s, D_loss=-78.5, G_loss=-40.4]\n",
      "Epoch 172/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.44it/s, D_loss=-88.4, G_loss=-38.4]\n",
      "Epoch 173/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.92it/s, D_loss=-92.5, G_loss=-39.9]\n",
      "Epoch 174/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.36it/s, D_loss=-90, G_loss=-37.9]  \n",
      "Epoch 175/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.45it/s, D_loss=-86.8, G_loss=-37]  \n",
      "Epoch 176/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.79it/s, D_loss=-86.5, G_loss=-37.8]\n",
      "Epoch 177/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.36it/s, D_loss=-84, G_loss=-38.4]  \n",
      "Epoch 178/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.93it/s, D_loss=-88.9, G_loss=-39] \n",
      "Epoch 179/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.69it/s, D_loss=-86.4, G_loss=-39]  \n",
      "Epoch 180/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.83it/s, D_loss=-91.6, G_loss=-40.4]\n",
      "Epoch 181/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.86it/s, D_loss=-84.3, G_loss=-39.7]\n",
      "Epoch 182/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.43it/s, D_loss=-84.3, G_loss=-40.1]\n",
      "Epoch 183/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.72it/s, D_loss=-79.6, G_loss=-40.8]\n",
      "Epoch 184/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.35it/s, D_loss=-83.3, G_loss=-40.1]\n",
      "Epoch 185/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.91it/s, D_loss=-85.5, G_loss=-39.6]\n",
      "Epoch 186/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.63it/s, D_loss=-83, G_loss=-38.1]  \n",
      "Epoch 187/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.82it/s, D_loss=-79.7, G_loss=-40.1]\n",
      "Epoch 188/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.31it/s, D_loss=-80.9, G_loss=-39]  \n",
      "Epoch 189/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.18it/s, D_loss=-82.7, G_loss=-39.2]\n",
      "Epoch 190/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.47it/s, D_loss=-82.7, G_loss=-40]  \n",
      "Epoch 191/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.25it/s, D_loss=-85.5, G_loss=-39.3]\n",
      "Epoch 192/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.57it/s, D_loss=-77.4, G_loss=-39.3]\n",
      "Epoch 193/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.67it/s, D_loss=-82, G_loss=-38.6] \n",
      "Epoch 194/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.46it/s, D_loss=-76.9, G_loss=-39.4]\n",
      "Epoch 195/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.68it/s, D_loss=-87.4, G_loss=-40.3]\n",
      "Epoch 196/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.20it/s, D_loss=-82.9, G_loss=-41.4]\n",
      "Epoch 197/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.90it/s, D_loss=-83.2, G_loss=-37.9]\n",
      "Epoch 198/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.50it/s, D_loss=-80.8, G_loss=-39.7]\n",
      "Epoch 199/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.43it/s, D_loss=-86, G_loss=-41]    \n",
      "Epoch 200/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.21it/s, D_loss=-81.7, G_loss=-40.3]\n",
      "Epoch 201/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.85it/s, D_loss=-82.7, G_loss=-41.3]\n",
      "Epoch 202/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.91it/s, D_loss=-77.8, G_loss=-39.6]\n",
      "Epoch 203/300: 100%|██████████| 1561/1561 [00:26<00:00, 59.46it/s, D_loss=-81.8, G_loss=-38.5]\n",
      "Epoch 204/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.47it/s, D_loss=-83.5, G_loss=-40.4]\n",
      "Epoch 205/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.49it/s, D_loss=-80.5, G_loss=-38.7]\n",
      "Epoch 206/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.61it/s, D_loss=-88.8, G_loss=-39.2]\n",
      "Epoch 207/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.65it/s, D_loss=-81, G_loss=-41.3]  \n",
      "Epoch 208/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.44it/s, D_loss=-77.2, G_loss=-41]  \n",
      "Epoch 209/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.52it/s, D_loss=-78.2, G_loss=-41.8]\n",
      "Epoch 210/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.32it/s, D_loss=-82.9, G_loss=-40.9]\n",
      "Epoch 211/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.12it/s, D_loss=-77, G_loss=-39.5]  \n",
      "Epoch 212/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.88it/s, D_loss=-81.2, G_loss=-40.2]\n",
      "Epoch 213/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.20it/s, D_loss=-79.2, G_loss=-40.8]\n",
      "Epoch 214/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.95it/s, D_loss=-80.7, G_loss=-42.1]\n",
      "Epoch 215/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.06it/s, D_loss=-75.7, G_loss=-40.7]\n",
      "Epoch 216/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.01it/s, D_loss=-79.3, G_loss=-39.9]\n",
      "Epoch 217/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.42it/s, D_loss=-83.6, G_loss=-40.7]\n",
      "Epoch 218/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.42it/s, D_loss=-76, G_loss=-40.8]  \n",
      "Epoch 219/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.72it/s, D_loss=-78, G_loss=-41.5]  \n",
      "Epoch 220/300: 100%|██████████| 1561/1561 [00:24<00:00, 63.54it/s, D_loss=-83.2, G_loss=-40.7]\n",
      "Epoch 221/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.94it/s, D_loss=-78.8, G_loss=-42.4]\n",
      "Epoch 222/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.01it/s, D_loss=-81.8, G_loss=-41.8]\n",
      "Epoch 223/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.11it/s, D_loss=-75.8, G_loss=-40.7]\n",
      "Epoch 224/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.61it/s, D_loss=-76.5, G_loss=-42.1]\n",
      "Epoch 225/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.36it/s, D_loss=-78.7, G_loss=-42.4]\n",
      "Epoch 226/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.77it/s, D_loss=-74.4, G_loss=-40.6]\n",
      "Epoch 227/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.71it/s, D_loss=-78.6, G_loss=-42.8]\n",
      "Epoch 228/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.67it/s, D_loss=-78.5, G_loss=-44.8]\n",
      "Epoch 229/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.69it/s, D_loss=-80.3, G_loss=-41.2]\n",
      "Epoch 230/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.32it/s, D_loss=-78, G_loss=-41.3]  \n",
      "Epoch 231/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.37it/s, D_loss=-70.9, G_loss=-41.3]\n",
      "Epoch 232/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.40it/s, D_loss=-73.1, G_loss=-45.1]\n",
      "Epoch 233/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.56it/s, D_loss=-78, G_loss=-42.6]  \n",
      "Epoch 234/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.60it/s, D_loss=-72.4, G_loss=-42.7]\n",
      "Epoch 235/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.68it/s, D_loss=-81.3, G_loss=-42.8]\n",
      "Epoch 236/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.57it/s, D_loss=-73.4, G_loss=-42.3]\n",
      "Epoch 237/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.90it/s, D_loss=-80.3, G_loss=-44.2]\n",
      "Epoch 238/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.16it/s, D_loss=-77.6, G_loss=-41.5]\n",
      "Epoch 239/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.65it/s, D_loss=-72.6, G_loss=-44.5]\n",
      "Epoch 240/300: 100%|██████████| 1561/1561 [00:26<00:00, 59.28it/s, D_loss=-74.6, G_loss=-42.4]\n",
      "Epoch 241/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.44it/s, D_loss=-70.6, G_loss=-42.3]\n",
      "Epoch 242/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.97it/s, D_loss=-78, G_loss=-42]    \n",
      "Epoch 243/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.21it/s, D_loss=-70.9, G_loss=-42.5]\n",
      "Epoch 244/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.73it/s, D_loss=-78.1, G_loss=-42.6]\n",
      "Epoch 245/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.54it/s, D_loss=-81, G_loss=-43.7]  \n",
      "Epoch 246/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.40it/s, D_loss=-75.7, G_loss=-44.2]\n",
      "Epoch 247/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.78it/s, D_loss=-78.4, G_loss=-42.8]\n",
      "Epoch 248/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.36it/s, D_loss=-76.3, G_loss=-42.4]\n",
      "Epoch 249/300: 100%|██████████| 1561/1561 [00:25<00:00, 62.10it/s, D_loss=-78.8, G_loss=-42.7]\n",
      "Epoch 250/300: 100%|██████████| 1561/1561 [00:24<00:00, 62.64it/s, D_loss=-75.7, G_loss=-44.9]\n",
      "Epoch 251/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.56it/s, D_loss=-84, G_loss=-43]    \n",
      "Epoch 252/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.40it/s, D_loss=-73.1, G_loss=-43.5]\n",
      "Epoch 253/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.00it/s, D_loss=-79.2, G_loss=-42.9]\n",
      "Epoch 254/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.48it/s, D_loss=-74.9, G_loss=-43]  \n",
      "Epoch 255/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.81it/s, D_loss=-74.9, G_loss=-43.1]\n",
      "Epoch 256/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.20it/s, D_loss=-78.6, G_loss=-43.2]\n",
      "Epoch 257/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.27it/s, D_loss=-71.5, G_loss=-44.4]\n",
      "Epoch 258/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.98it/s, D_loss=-74.3, G_loss=-44.6]\n",
      "Epoch 259/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.97it/s, D_loss=-74.6, G_loss=-44.4]\n",
      "Epoch 260/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.53it/s, D_loss=-69.6, G_loss=-43]  \n",
      "Epoch 261/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.25it/s, D_loss=-74.3, G_loss=-42.1]\n",
      "Epoch 262/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.04it/s, D_loss=-69.5, G_loss=-43.2]\n",
      "Epoch 263/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.12it/s, D_loss=-70, G_loss=-44.8]  \n",
      "Epoch 264/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.39it/s, D_loss=-66.1, G_loss=-46.8]\n",
      "Epoch 265/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.41it/s, D_loss=-73.9, G_loss=-43.4]\n",
      "Epoch 266/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.91it/s, D_loss=-65.6, G_loss=-42]  \n",
      "Epoch 267/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.92it/s, D_loss=-75.2, G_loss=-43.5]\n",
      "Epoch 268/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.66it/s, D_loss=-80.4, G_loss=-43.8]\n",
      "Epoch 269/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.34it/s, D_loss=-73, G_loss=-43.8]  \n",
      "Epoch 270/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.06it/s, D_loss=-72, G_loss=-43.1]  \n",
      "Epoch 271/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.20it/s, D_loss=-71.3, G_loss=-44.5]\n",
      "Epoch 272/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.77it/s, D_loss=-67, G_loss=-40.9]  \n",
      "Epoch 273/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.27it/s, D_loss=-66.7, G_loss=-41.4]\n",
      "Epoch 274/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.98it/s, D_loss=-69.5, G_loss=-44]  \n",
      "Epoch 275/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.46it/s, D_loss=-74.2, G_loss=-44.2]\n",
      "Epoch 276/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.23it/s, D_loss=-70.9, G_loss=-42.2]\n",
      "Epoch 277/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.57it/s, D_loss=-63.7, G_loss=-43]  \n",
      "Epoch 278/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.42it/s, D_loss=-73.9, G_loss=-42.9]\n",
      "Epoch 279/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.28it/s, D_loss=-69, G_loss=-41.4]  \n",
      "Epoch 280/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.40it/s, D_loss=-71.3, G_loss=-43.2]\n",
      "Epoch 281/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.50it/s, D_loss=-74.6, G_loss=-42.6]\n",
      "Epoch 282/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.00it/s, D_loss=-72.8, G_loss=-42.3]\n",
      "Epoch 283/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.68it/s, D_loss=-65.2, G_loss=-41.7]\n",
      "Epoch 284/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.63it/s, D_loss=-71.1, G_loss=-43]  \n",
      "Epoch 285/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.64it/s, D_loss=-71, G_loss=-41.3]  \n",
      "Epoch 286/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.33it/s, D_loss=-69.5, G_loss=-42.6]\n",
      "Epoch 287/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.60it/s, D_loss=-72.3, G_loss=-42.1]\n",
      "Epoch 288/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.88it/s, D_loss=-66, G_loss=-43.5]  \n",
      "Epoch 289/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.88it/s, D_loss=-71.8, G_loss=-43.8]\n",
      "Epoch 290/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.41it/s, D_loss=-73.9, G_loss=-41.4]\n",
      "Epoch 291/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.44it/s, D_loss=-69.8, G_loss=-42.1]\n",
      "Epoch 292/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.00it/s, D_loss=-64.8, G_loss=-43]  \n",
      "Epoch 293/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.40it/s, D_loss=-72.1, G_loss=-43.9]\n",
      "Epoch 294/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.49it/s, D_loss=-70.7, G_loss=-42.5]\n",
      "Epoch 295/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.92it/s, D_loss=-67.2, G_loss=-40.7]\n",
      "Epoch 296/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.96it/s, D_loss=-70.5, G_loss=-43]  \n",
      "Epoch 297/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.62it/s, D_loss=-71.8, G_loss=-42.8]\n",
      "Epoch 298/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.68it/s, D_loss=-67.8, G_loss=-41.3]\n",
      "Epoch 299/300: 100%|██████████| 1561/1561 [00:25<00:00, 60.44it/s, D_loss=-67.9, G_loss=-41] \n",
      "Epoch 300/300: 100%|██████████| 1561/1561 [00:25<00:00, 61.77it/s, D_loss=-68.1, G_loss=-42.2]\n"
     ]
    }
   ],
   "source": [
    "gan = WGAN_GP(embed_dim=256, n_epochs=300, batch_size=64)\n",
    "dataloader = gan.load_data(r'C:\\Users\\mokht\\Desktop\\GAN-Drug-Generator\\my_implementations\\data\\x_latent.csv')\n",
    "gan.train(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (l1): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (1): BatchNorm1d(256, eps=0.9, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "    )\n",
       "    (1-4): 4 x Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): BatchNorm1d(256, eps=0.9, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.3, inplace=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator(embed_dim=256).to(device)\n",
    "\n",
    "model_path = 'models/WGAN-GP/Generator/generator_468299.pth'\n",
    "generator.load_state_dict(torch.load(model_path, map_location=device))\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.35021526, -2.2307417 , -1.182814  , ..., -0.15295151,\n",
       "         0.7470438 , -2.2020862 ],\n",
       "       [-2.1950119 , -0.5898259 , -2.7986877 , ..., -1.8145192 ,\n",
       "        -0.12460481, -1.4324212 ],\n",
       "       [-1.852866  , -0.7882663 , -1.8729928 , ..., -1.7834963 ,\n",
       "        -0.81860936, -4.0026813 ],\n",
       "       ...,\n",
       "       [-1.5491042 , -1.0730036 , -0.6725843 , ..., -0.5438398 ,\n",
       "         1.3668118 , -1.8061458 ],\n",
       "       [-1.2316313 , -0.58931166, -2.2032902 , ..., -1.3313978 ,\n",
       "        -0.61973006, -3.7928548 ],\n",
       "       [-2.542143  , -0.6158922 , -1.2796801 , ..., -1.2782576 ,\n",
       "        -0.36727083, -3.5691664 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_samples = 100\n",
    "noise_dim = 256\n",
    "\n",
    "# Generate random noise vectors\n",
    "z = torch.tensor(np.random.uniform(-1, 1, (num_samples, noise_dim)), dtype=torch.float32, device=device)\n",
    "\n",
    "# Generate embeddings using the GAN's generator\n",
    "with torch.no_grad():\n",
    "    generated_embeddings = generator(z).cpu().detach().numpy()  # Convert directly to NumPy array\n",
    "    \n",
    "generated_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Decoding SMILES: 100%|██████████| 100/100 [3:06:05<00:00, 111.65s/ latent]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CNC1=O)c(C=C(c2ccc3cc(OC)ccc3c2)NC2C(=O)Nc3cc(sc4ccc(c(=S)c(F)c3N5)CC14)C[C@H]2O', 'CNC1=O()CC(=COc2ccc(Nc3ccc3)c(F)c2CNc2cc(N)cc(-c3ccc(Sc4cccc4)c3)c2)CO1', 'CNC1=O()CC(=O)c2cc(Nc3cc(O)cc4nc5cc(OC)c5sc(c1)c(=NO)c35)Co2', 'CNC1=C(O)CC(c2ccc3cc(O)c4cc(F)c3c(OC)c3CN(C)c5ccc(=S)n(c2F)CH3)C1CCO5)O', 'CCCC)c1ccc(C(=O)Cc2cc(OC)cc3c(F)c(OC)c4cc(NC)cc(-c5ccc(S(=O)(=O)ccc5N)c4C)cc23)cc1O', 'CCC1)C(OCC(=O)Cc2cc(NCc3cc(C)nc4c3CN(Cc3c#N)c(=S)nc3c4)co2)C1O', 'CC9=O)(OCC(=O)Cc1cc(Oc2cc3c(N)c4C(=O)Nc4cc4cc(N)oc(S)c(c(=O)c4c2O)co3)cc1CO', 'CCC1)Cc2cc(C(=O)Cc3cc(NC)c(C=O)c4OC(=O)-c4c[nH]c(=O)oc3c1OCC2', 'CCC1=O)c(NC(=O)c2cc(Nc3cc(F)c4cc(NC)c5c(N)c(=S)c(F)cc6[nH]c35)co2)cc1O', 'CNC3=C(CO)C(=Cc1ccNc2cc(F)c3C(=O)Nc4cc(=S)c(Ccc14)CC3)O2', 'cc(N)c(Cc2ccc3cc(NN)cc4nc3c(N=c3c(N)sc(-c5cc(F)c(=O)n5CCO)c23)CC4)c1', 'CCN1C(O)CNC(Cc2cnc3cc(N)c4nc(N)c5C(N)c(=S)c(=nc5c2)N3CC)C14', 'CC9=S(O)CC(c1ccc2cc(OC)c3cc(N)c4C4C(=O)c4cc(N)cc5sc(c(=O)c1c(N2C)C[C@H]65)c4)CO3', 'CNC1=O)c(C=C(Nc2ccc3cc(O)ccc3N)c(OC)c2C(Nc2cc(=N)sc3)c(c(=O)c2N3CCC1)c1ccccc1', 'CNC1=O)C(CC(=O)c2cc(NCO)c3cc(F)cc4c(F)c3CN()cc(-c3ccc(S(=O)F)cc3)c2CC)c1O', 'CCCC)C(OCC(=O)Cc1cc(NCO)c2cc(F)c3cc(OC)c(CN)c(-c4ccc(S(=O)(=O)ccc4N)c1CC3)cO2', 'CNC1=C(CO)CC(=Nc2cc(OC)cc3cc(NC)c4C(=O)Nc5cc(Br)cc(c5nc2CO4)C3)CO1', 'CNC12C(CC(=O)Cc3cc(OCN)c4c(OC)c(NC4C(=O)Nc4ccc(Br)cc(=O)c(OC)c43)c1CC2)CO', 'CNC1=O)C(C=C(c2ccc3cnc(N)cc3C)c(NC3Cc4cc(N=)c5ccc(-c5cc(Cl)sc5)cn4C13)c2C', 'NC9=C(O)CC(OCc1ccc2cc(N)c3c(F)c4C(F)c4cc(Br)cc4cc(c(=O)c1N4CCO)o3)c2O', 'CNC1=O()Cc2cc(cc3cc(Nc4cc1)c(F)c5cc(NC4=C(N)S)c(c1ccc(-c4cc(O)ccc5N1)o4)CO3)c2O', 'CNC1=O)C(CF)c(c2ccc3Nc4cc(O)cc4C3C(Nc3c)oc(F)c(c2SC)c3)c1O', 'CCC=O)C(OCC(=O)Cc1cc(OC)c2cc(N)c(OC)c3C(Nc4ccc(Br)ccc(-c5cc(O)ccc5C4)c1)CC32)O', 'CNC1=O()CC(=Cc2cc(OC)cc3N)c(C=O)c3Cc1cc(N)cc(=S)c(cc2OC)c2', 'NC1=C(O)CC(c2ccc(OCc3cc(O)cs3)c(OC3C(F)c4csc(N)cc4cc(S(=O)(=O)N1CCO)c2)Cc3ccccc1', 'CC9=Oc1cnc(Cc2ccc(Nc3ccc3)c(FF)c3C(N)c(=S)cc(=O)[nH]c2CC13', 'CNC1=C(O)CC(c2ccc3cc(O)c4cc3c(F)c3c(OC)c(CN)cc5scc(c1c(=O)[nH]c5c2)CC3)c4O', 'CCC1=O)C(CC(=O)Cc2cc(OC)c(N)c2C(=O)NC2Cc3cc(N)cc(-c4ccc(S(=O)(=O)O)cc4N2)co3)CO1', 'CCC1=O)NC(Cc2ccc3cc(NC)c4cc(F)c5CNC(c6cc1)sc(-c6cc(=O)oc6c5)c[nH]c2C34)c1', 'CNC1=O()Cc(C(=O)Nc2cc(O)cc3c2)c(NC2Cc4cc(N)cc(=S)cc4[CH]2)CC3O1', 'O=c18CNCc2cc(c3CNc4ccc(N)cc4nc4cc(NC(=O)Nc5cc(Br)cc(=n5)c(c4F)N)C13)c1cC[cH-]cc12', 'CNC1=O)C(CC(=O)c2cc(NCc3ccccc3)c(OC)c3C(=O)Nc4cc(Br)cc(=C(c5ncc1O)c5)c4Cc23', 'CC9=Oc1cnc(C(=O)c2cc(NO)cc3c)c(NC3Cc3c(N)sc4cc(S(=O)F)c2c43)cc1O', 'CCC6)=C(CO)C(=Cc1ccc(OC)c2cc(NC)c(=O)OC3C(=O)N(c4nc(Br)cc(=O)c5nc1[CH]2)C[C@]354)HO', 'CCN=c1c(OCC(c2ccc3cc(ON)c4cc3C)c(NC3Cc5cc(N)cc5occ(c15)C(=O)N3CC2)C4)cc1O', 'CNC1=O)c(CC(=O)c2cc(NCc3cc(O)sc3CO)c(-c3cc(N)cc4occ(c(=O)c4F)CN13)c2CCO', 'N=C(O)CNC(Cc1cc2cc(NF)ccc2c1)Nc1cc2nc(Nc3cc(N)cc(=C(=O)C(F)(c4cccc1)N1CC1)C3)cc2', 'NC9=O()CC(=O)C(Nc1cc(O)cc2N)c(CO)c3nc4cc(N)cc5c(=S)c(c(O)cc1c2N)C[C@]456', 'CNC=O()c1ccc(C(=O)Cc2cc(ON)c3c(F)c(OC)c4c(Nc5cc(N)cc(=S)c(c5ccc2O)c5)co4)cc13', 'NC1=C(NC)C(c2ccc3cc(N)cc3F)c2CNc2c(F)sc(S)c(c3ncc1c23)O', 'CC9(=O)OCC(c1ccc2cc(OC)c3cc2c(F)c4cc2C(N)Cc5cc(=S)c(F)c(c5cc1O2)CC43C)c1ccccc1', 'CNC1=O)C(Cc(=O)c2cc(Nc3cc(F)cc3F)c3cc(NC)c4scc(c4c(F)c23)CO)C1', 'CC1(c2ccc(C(=O)Cc3cc(O)c4cc3)-4C3C(F)c4c-c5cc(N)oc(c5c(=O)[nH]c1c4)CC32O', 'NC9=O(O)CC(Cc1ccc(OCc2cc3c(N)c(OC)c4c(NCc5c)c(N)cc(=5nc(cc1O)c5)co4)cc32)CO', 'CNC3=O(CCF)C(c1ccc2CNc3cc(C)c(=ON)c3C(N)cc4scc(c(=O)n1)C4)C[CH22', 'CNC1(O)CC(C(=O)Cc2cc(ON)c3cc(OC)c4c(NC4Cc4cc(N)cc(-c5nc(Cl)ccc5N4)co2)C3)cc1O', 'CNC=O)C(NC(=O)Cc1cc(NCc2cc(F)c(OC)c(Nc3cc(N)oc(=O)c(-c4ccn4)c3)c2)cc1O', 'CCN1=OCC(C(=O)Cc2cnc3cc(N)c4C(F)c4CN(c4ccc5)-c5cc(oc5cc2)N1CC3)O4', 'Nc1ccc(NCC(c2cc3CNc4ccccc3F)c3sc(Nc4cc(-c5ccc(=)n5)cc(c4F)CC13)o2)c1ccccc1', 'CNC1(O)CC(C(=O)Nc2cc(OC)c3cc(N)c4C5Cc(N)c(-c5ccc(Cl)cc5)cc2NC34)CO1', 'CNC1)c2cnc(C(=O)Cc3cc(NO)c(C)c4NC(=O)C3CN()c-c5ccc(Cl)c(F)c5N1)C[CH+]2', 'CCC1)Cc(NCc2ccc3cc(N)c4C(F)c4cc(N)c(=S)coc23)cc1', 'CCC1)c2cnc(C(=O)Nc3cc(OC)c(=O)c4cN(C=O)c5c(OC)c(Br)c(=O)n(c5cO)c1[C@H]4C)c32', 'NC9=O(O)CC(Cc1ccc(OCc2cN3)c(F)c4CNc5cc(F)cc5scc(c6cc(cc15)NCC6)C32)O4', 'NC9=O)(NCC(c1ccc2cc(OC)c3cc(N)c4C(F)c4CN()cc4scc(c1)c(=O)cc4c1cCO1)c3CC2', 'CNC=O()Cc1cc(C(=O)c2cnc3cc(N)cc4nc3cc3NC(c5ccc(Br)cc(-c5cc(Cl)ccc5N)o2)C3)cc1O', 'CC9=C(O)CC(c1ccc2cc(OC)c3c(N)c4C5C(=O)c5csc(N)cc5c(=S)c(c1cc2O)CC43C)c1ccccc1', 'CNC1=O)C(C(=O)Cc2cc(OCc3cc(N)cc(C)c3C(=O)Nc3cc(N)cc(=S)c(F)cc3c(O)c[nH]2)C1Cc1ccccc1', 'CNC1=C(O)CC(c2ccc(Oc3cc(N)c4)c(OC)c4c(NCc4cc(N)cc(=S)c(F)c4cc1O)[C@H]3)cc2CO', 'CCCC1C(O)CC(NCc2ccc(OC)c3cc(N)cc4C(=O)Nc5cc(Br)cc(-c5cc(Cl)cc5N2)co4)CO3)C1O', 'CNC(=O)CC(Cc1cc(Nc2cc(OC)c3cc(NC)c4cc(OC)c5c(N)oc(cc5c(=O)nH]c2c43)CO)cc1)O', 'CNC1=O)C(CF)c(c2Cc3cc(NF)cc3c2)nc2Nc3cc(NC(=O)c4csc(c(=O)c5cc(F)cn45)c1CC3)c2', 'CC9=C(O)CC(C(=O)Cc1cc(O)c2cc(N)c3C(OC)c4cc(NC)c(-c5ccc(SC(=O)c6ccccc6)c5[nH]4)cc1c32', 'CNC1=O)C(Cc2ccc(Cc3ccNc4C)c(F)c3CNc3cc(F)cc4scc(c(=S)c2F)N4CC1)c1ccccc1', 'CNC1=O)cc(Cc(c2ccc(OCc3cN)c(C)c4nc5cc(N)c6cc(Br)cc(c6cc1F)c4cc23)CO5', 'CNC1=O)CC(C(=O)c2cc(CNc3cc(C)c(F)cc3C)c(N=S)c3ccc(F)c(cc2S)c13)Cc4ccccc4', 'NN=c1ccc(nc(cc3cc2c(NF)ccc3c2)Nc3cc(NC(=O)c4cc(N)cc(-c5cc(Cl)ccc5)c4N)co13)c1ccccc1', 'CNc1cc(OC)c(Cc2cc(Nc3ccccc3F)c(N)c3CNc4cc(F)c(Br)cc(-c5cc(F)cc54)n23)Cc2ccoc12', 'CCC1)OC(Cc2cc(NCc3cc(O)c5c-3CO)c(N=C)c(N)cc(=S)c(c3ccNc23)CO1)O', 'CNc1ccc(NCc2cc(CNc3ccccc3N)nc3cc4NC(c5cc(N)cc(=S)c(-c5cncc45)cn2)C3)cc1', 'CNC1=O)c(CC(=Oc2ccc3cc(NO)c(C)c4nc5c(N)c6C)c(scc(c16)c(=O)c2N3CC6)CO6', 'NC9=O()c1ccc(C(=O)c2cc(ON)c3cc(F)c4c(OC)c5cc(N)cc5sc(cc6c(=O)c1c23)OC[C4)c6cc6', 'NC9=O(O)CC(Cc1ccc(OCc2cN3)c(F)c4CNc5cc(F)c5cc(Br)cc(c5cc1nc23)CC4)c1ccccc1', 'CNC1=C(O)CC(=Nc2ccc3cc(N)cc4c3CF)c(CNc3ccc(Br)cc(=Cn4cccc4)c3)c1CC2', 'CNC1=O)c(CC(=O)c2cc(OCc3cc2)c(NC3Cc4cc(F)cc4scc(I)c(=O)c3c2OCC3)C2cccc2)c1', 'CNC1=C(O)CC(c2ccc3cc(OC)c4c(N)c5C(=O)Nc5cc4cc(N)oc(c3c(=O)c2F)CN2CC2)CO1', 'CCC=O)NC(Cc1ccc(NCc2cc(F)c3cN(C)c(Fc4cc(N)sc(=O)c4cs2)C3)cc1O', 'CNC1c2cnc(C(c3ccc4cc(NF)cc4c3)NC3C(=O)Nc4cc(sc4)c(=NC(c4ccccc4)N1C)o3)CO2', 'CCN=c1ccc(C(=O)Cc2cc(OCN)c3cc(F)c4c(NC4Cc4)c(N)cc(=Sc4cc(F)ccc4N1C)co2)CO3', 'CNC1=O)c(nc(c2ccc3cc(NO)c(C)c4NC(=O)c4cc(N)c(=S)c(F)cc4c(c2N)CC1)CO4)O3', 'CNC1=O)C(CC(=O)Cc2cc(NCO)c3cc(F)c4cc(OC)c(CN)cc(-c5ccc(S(=O)O)cc5cc2)CC43)cc1O', 'CNC1=O()CC(=O)C(c2ccc(OC)c3cc(N)c4C(=O)NC4cc(N)cc(-c4ccc(S(=O)O)cc4)c2CC3)CO1', 'CCC1)C(OCC(=O)Cc2cnc3cc(N)cc4C)c(NC3Cc3c(N)sc(=O)c(-c5nc1c1)co2)CO5', 'CNC1(=O)C(OCc2cc(ccc2O)c2c(N)c3C(F)c4Cc4cc(N)cc4sc(c(=O)c1c2O)Co1)c4ccoc3O', 'CCC1=O)nc(Cc2ccc(NCc3cc(F)c4cNC(=O)CN(c5cc(=N)oc(F)c5C4)cc3)o2)c1', 'NC1=C(O)CC(Cc2cc(Nc3cc(O)cc3)c3nc4cc(N)c(-c5ccc(Cl)c(F)c5cc2)cc43)CO1', 'N=C1c(NCc2cc(c3cc(N=O)ccc3N)c(OC)c3cc(N=O)c4c(N)cc(=S)c(cc4c2F)C(N)C3)Cc2ccccc21', 'CNC1=C(O)CC(c2ccc(OC)c3c(N)c(=O)c4nc4c(N)c(S)c(=O)c(-c5cc(OC)ccc52)C3)CO1', 'NC9=O(O)CC(Cc1ccc(OCc2cN)c(F)c3c2OC(=O)c4cc(Br)cc(c5cc(F)cc5[nH]4)cc13)CO', 'CNC1=C(O)CC(Cc2ccc(OC)c3c(N)c2C(=O)NC2Cc4cc(N)cc(=S)c(cc4OC(c2)CC3)CO)c1', 'CC9=C(O)CC(C(=O)c1cc(OCc2c3cc(N)oc3c(OC)c3cc(N)c(=S)cc4cc(F)c(c1c24)OC)c13Cc1', 'CNC1=+]c2cc(C(=O)c3cc(NO)c4cc(F)c5c(OC)c(CN)c(S)cc(=F)c(c5cc3O)[CH]oc4c1)CO2', 'CC9=OC(O)CC(Cc1ccc(OC)c2cc(N)c3C(=O)NC3cc(N)cc3ccc(-c4ccc(c1=O)N4CC)c2)Cc3ccHOc', 'NC1=C(O)CC(=Cc2cc3cc(NF)ccc3c2)NC2Cc3cc(Nc4cc(=Br)nc(c5cc(F)cc45)c[nH]3)C1CC2', 'CNC1=O)CC(Cc2ccc(cc2F)CN2)C(C=O)c3cc(N=)c4ccc(c(=S)cc1OC)c2c3', '=C1OC(=O)C(Cc2ccc3cc(O)c4c3c2C(=O)c2Cc3cc(F)ccc3sc(S(=O)(=O)c3cc12)OCO3)C4C', 'CNC1=O(CCF)c(Cc2cc(NC)cc2F)c2CNC(c3cc(=N)ccc(-c4ccScc4)c3)CO12', 'CNC1=O(C)Cc2cc(ccc2CNc2cc(F)c3CNc4cc(F)c(N=)c5ccc(c(F)cc5N4)co1)C32', 'CC9=O)(CC(=O)C(Nc1cc2cc(O)cc3c2)nc2c(NC4)c(S)sc(c(=O)c1OC2)CC3', 'CNC1=O(CCF)c(cc2ccc3Nc2)c(C=O)c2c(N)c(=S)c(=Ooc12)CO3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Decode each latent vector to SMILES\n",
    "decoded_smiles = []\n",
    "for latent in tqdm(generated_embeddings, desc=\"Decoding SMILES\", unit=\" latent\"):\n",
    "    # Convert NumPy array to TensorFlow tensor\n",
    "    tf_latent = tf.convert_to_tensor(latent.reshape(1, -1), dtype=tf.float32)\n",
    "    # Decode the latent vector to SMILES\n",
    "    smile = autoencoder.latent_to_smiles(tf_latent, vocab)\n",
    "    decoded_smiles.append(smile)\n",
    "\n",
    "# Print or store the decoded SMILES strings\n",
    "print(decoded_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'SMILES': 'CCN1C(O)CNC(Cc2cnc3cc(N)c4nc(N)c5C(N)c(=S)c(=nc5c2)N3CC)C14', 'MolecularWeight': 467.60300000000024, 'LogP': -0.600399999999996}, {'SMILES': 'CNC1=C(CO)CC(=Nc2cc(OC)cc3cc(NC)c4C(=O)Nc5cc(Br)cc(c5nc2CO4)C3)CO1', 'MolecularWeight': 582.455, 'LogP': 3.116200000000002}, {'SMILES': 'CNC1(O)CC(C(=O)Cc2cc(ON)c3cc(OC)c4c(NC4Cc4cc(N)cc(-c5nc(Cl)ccc5N4)co2)C3)cc1O', 'MolecularWeight': 621.0940000000002, 'LogP': 3.1654000000000018}, {'SMILES': 'N=C1c(NCc2cc(c3cc(N=O)ccc3N)c(OC)c3cc(N=O)c4c(N)cc(=S)c(cc4c2F)C(N)C3)Cc2ccccc21', 'MolecularWeight': 635.725, 'LogP': 7.1068600000000055}]\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "# Function to compute molecular properties\n",
    "def calculate_properties(smiles_list):\n",
    "    properties = []\n",
    "    for smile in smiles_list:\n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        if mol:\n",
    "            mw = Descriptors.MolWt(mol)\n",
    "            logp = Descriptors.MolLogP(mol)\n",
    "            properties.append({'SMILES': smile, 'MolecularWeight': mw, 'LogP': logp})\n",
    "    return properties\n",
    "\n",
    "# Assuming `decoded_smiles` is your list of SMILES strings\n",
    "properties = calculate_properties(decoded_smiles)\n",
    "print(properties)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
