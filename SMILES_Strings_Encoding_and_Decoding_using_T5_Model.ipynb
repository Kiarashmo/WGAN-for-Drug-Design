{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from tokenizers import Tokenizer, Regex\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import Split\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:54:43] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:54:46] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:54:47] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:54:49] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:54:49] Explicit valence for atom # 12 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: c1c(c(ncc1)CSCCN\\C(=[NH]\\C#N)NCC)Br\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:54:50] Explicit valence for atom # 6 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: Cc1nc(sc1)\\[NH]=C(\\N)N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:54:51] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[01:54:51] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: c1(cc(N\\C(=[NH]\\c2cccc(c2)CC)C)ccc1)CC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:54:52] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:54:53] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[01:54:53] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)NC(C)=O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:54:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:54:57] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:54:59] Explicit valence for atom # 1 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: O=N([O-])C1=C(CN=C1NCCSCc2ncccc2)Cc3ccccc3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:55:01] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:55:05] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "[01:55:05] Explicit valence for atom # 11 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: c1(nc(NC(N)=[NH2])sc1)CSCCNC(=[NH]C#N)NC\n",
      "Unable to parse SMILES: s1cc(CSCCN\\C(NC)=[NH]\\C#N)nc1\\[NH]=C(\\N)N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:55:07] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[01:55:07] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: n1c(csc1\\[NH]=C(\\N)N)c1ccccc1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:55:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:55:09] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:55:10] Explicit valence for atom # 5 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: s1cc(nc1\\[NH]=C(\\N)N)C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:55:15] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[01:55:15] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:55:16] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:55:18] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:55:20] Explicit valence for atom # 5 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)N\\C(NC)=[NH]\\C#N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[01:55:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:55:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:55:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:55:25] WARNING: not removing hydrogen atom without neighbors\n",
      "[01:55:26] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after preprocessing: (99849, 1)\n",
      "Maximum SMILES length in dataset: 100\n",
      "SMILES strings with the maximum length:\n",
      "59012    CC1(C)C(=O)CC[C@@]2(C)[C@H]3C(=O)C=C4[C@H]5C[C...\n",
      "69959    CC1(C)[C@@H](O)CC[C@@]2(C)[C@H]3CC=C4[C@H]5C[C...\n",
      "Name: SMILES, dtype: object\n"
     ]
    }
   ],
   "source": [
    "file_path_vae_train = r'C:\\Users\\mokht\\Desktop\\CBRC_ED_Project\\data\\composed_dataset_100k.csv'\n",
    "df_vae_train = pd.read_csv(file_path_vae_train, names=['SMILES'])\n",
    "\n",
    "def canonicalize_smiles(smiles):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is not None:\n",
    "            return Chem.MolToSmiles(mol, canonical=True)\n",
    "        else:\n",
    "            print(f\"Unable to parse SMILES: {smiles}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "df_vae_train['SMILES'] = df_vae_train['SMILES'].apply(canonicalize_smiles)\n",
    "df_vae_train.dropna(subset=['SMILES'], inplace=True)\n",
    "df_vae_train.drop_duplicates(subset=['SMILES'], inplace=True)\n",
    "print(\"Dataset shape after preprocessing:\", df_vae_train.shape)\n",
    "\n",
    "df_vae_train['length'] = df_vae_train['SMILES'].apply(len)\n",
    "max_length = df_vae_train['length'].max()\n",
    "longest_smiles = df_vae_train[df_vae_train['length'] == max_length]\n",
    "print(\"Maximum SMILES length in dataset:\", max_length)\n",
    "print(\"SMILES strings with the maximum length:\")\n",
    "print(longest_smiles['SMILES'])\n",
    "\n",
    "preprocessed_file_path = r'C:\\Users\\mokht\\Desktop\\CBRC_ED_Project\\data\\preprocessed_composed_dataset_100k.csv'\n",
    "df_vae_train.to_csv(preprocessed_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Reload Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cc1cc(NC(=O)COC(=O)COc2ccc3c4c(c(=O)oc3c2)CCC4...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cn1c2c([N+](=O)[O-])cccc2c(=O)c2c(O)cc3c(c21)C...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C=C[C@]1(C)CC[C@H]2C(=C[C@@H]3OC(=O)[C@]4(C)[C...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COc1cc(CC[C@H](C[C@@H](OC(C)=O)[C@@H]2CCCCC[C@...</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cn1ccoc1=Nc1ccc(Cl)c(Cl)c1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              SMILES  length\n",
       "0  Cc1cc(NC(=O)COC(=O)COc2ccc3c4c(c(=O)oc3c2)CCC4...      50\n",
       "1  Cn1c2c([N+](=O)[O-])cccc2c(=O)c2c(O)cc3c(c21)C...      57\n",
       "2  C=C[C@]1(C)CC[C@H]2C(=C[C@@H]3OC(=O)[C@]4(C)[C...      73\n",
       "3  COc1cc(CC[C@H](C[C@@H](OC(C)=O)[C@@H]2CCCCC[C@...      69\n",
       "4                         Cn1ccoc1=Nc1ccc(Cl)c(Cl)c1      26"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vae_train = pd.read_csv(preprocessed_file_path)\n",
    "df_vae_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenizer Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load and Configure Custom Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_tokenizer = Tokenizer(\n",
    "    WordLevel.from_file(\n",
    "        '/smiles-Word/vocab.json',\n",
    "        unk_token='[UNK]'\n",
    "    )\n",
    ")\n",
    "custom_tokenizer.pre_tokenizer = Split(\n",
    "    pattern=Regex(r\"(\\[[^\\]]+]|Br?|Cl?|N|O|S|P|F|I|b|c|n|o|s|p|\\(|\\)|\\.|=|#|\\+|\\\\|\\/|:|@|\\?|>|>>|\\*|\\$|\\%[0-9A-Fa-f]{2}|[0-9])\"),\n",
    "    behavior='isolated'\n",
    ")\n",
    "\n",
    "hf_tokenizer = PreTrainedTokenizerFast(tokenizer_object=custom_tokenizer)\n",
    "hf_tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "hf_tokenizer.save_pretrained('/smiles-Word')\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"/smiles-Word/tokenizer.json\")\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Define Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMILESDataset(Dataset):\n",
    "    def __init__(self, smiles_list, tokenizer, max_length=512):\n",
    "        self.smiles_list = smiles_list\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smiles = self.smiles_list[idx]\n",
    "        input_encodings = self.tokenizer(smiles, truncation=True, padding='max_length', max_length=self.max_length)\n",
    "        target_encodings = self.tokenizer(smiles, truncation=True, padding='max_length', max_length=self.max_length)\n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_encodings['input_ids']),\n",
    "            'attention_mask': torch.tensor(input_encodings['attention_mask']),\n",
    "            'labels': torch.tensor(target_encodings['input_ids'])\n",
    "        }\n",
    "\n",
    "smiles_data = df_vae_train['SMILES'].tolist()\n",
    "dataset = SMILESDataset(smiles_data, tokenizer, max_length=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Verify Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original SMILES: Cc1cc(NC(=O)COC(=O)COc2ccc3c4c(c(=O)oc3c2)CCC4)no1\n",
      "Tokenized input_ids: [16, 15, 20, 15, 15, 17, 23, 16, 17, 22, 19, 18, 16, 19, 16, 17, 22, 19, 18, 16, 19, 15, 21, 15, 15, 15, 26, 15, 32, 15, 17, 15, 17, 22, 19, 18, 44, 15, 26, 15, 21, 18, 16, 16, 16, 32, 18, 25, 44, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Tokenized tokens   : ['C', 'c', '1', 'c', 'c', '(', 'N', 'C', '(', '=', 'O', ')', 'C', 'O', 'C', '(', '=', 'O', ')', 'C', 'O', 'c', '2', 'c', 'c', 'c', '3', 'c', '4', 'c', '(', 'c', '(', '=', 'O', ')', 'o', 'c', '3', 'c', '2', ')', 'C', 'C', 'C', '4', ')', 'n', 'o', '1', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "--------------------------------------------------------------------------------\n",
      "Original SMILES: Cn1c2c([N+](=O)[O-])cccc2c(=O)c2c(O)cc3c(c21)C=CC(C)(C)O3\n",
      "Tokenized input_ids: [16, 25, 20, 15, 21, 15, 17, 41, 17, 22, 19, 18, 36, 18, 15, 15, 15, 15, 21, 15, 17, 22, 19, 18, 15, 21, 15, 17, 19, 18, 15, 15, 26, 15, 17, 15, 21, 20, 18, 16, 22, 16, 16, 17, 16, 18, 17, 16, 18, 19, 26, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Tokenized tokens   : ['C', 'n', '1', 'c', '2', 'c', '(', '[N+]', '(', '=', 'O', ')', '[O-]', ')', 'c', 'c', 'c', 'c', '2', 'c', '(', '=', 'O', ')', 'c', '2', 'c', '(', 'O', ')', 'c', 'c', '3', 'c', '(', 'c', '2', '1', ')', 'C', '=', 'C', 'C', '(', 'C', ')', '(', 'C', ')', 'O', '3', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    smiles = smiles_data[i]\n",
    "    tokenized_output = tokenizer(smiles, truncation=True, padding='max_length', max_length=max_length)\n",
    "    print(f\"Original SMILES: {smiles}\")\n",
    "    print(f\"Tokenized input_ids: {tokenized_output['input_ids']}\")\n",
    "    print(f\"Tokenized tokens   : {tokenizer.convert_ids_to_tokens(tokenized_output['input_ids'])}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Load and Train T5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mokht\\anaconda3\\Lib\\site-packages\\accelerate\\accelerator.py:451: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3448fa35776447edad215b83737e0575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24964 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.514, 'grad_norm': 0.631125807762146, 'learning_rate': 4.9018193475995835e-05, 'epoch': 0.04}\n",
      "{'loss': 0.0499, 'grad_norm': 1.0503255128860474, 'learning_rate': 4.801635008415485e-05, 'epoch': 0.08}\n",
      "{'loss': 0.0305, 'grad_norm': 0.3795585036277771, 'learning_rate': 4.701450669231386e-05, 'epoch': 0.12}\n",
      "{'loss': 0.0209, 'grad_norm': 0.489401638507843, 'learning_rate': 4.6012663300472876e-05, 'epoch': 0.16}\n",
      "{'loss': 0.017, 'grad_norm': 0.8533644676208496, 'learning_rate': 4.5010819908631885e-05, 'epoch': 0.2}\n",
      "{'loss': 0.0136, 'grad_norm': 0.2048753798007965, 'learning_rate': 4.4008976516790894e-05, 'epoch': 0.24}\n",
      "{'loss': 0.0118, 'grad_norm': 0.3870348632335663, 'learning_rate': 4.300713312494991e-05, 'epoch': 0.28}\n",
      "{'loss': 0.0108, 'grad_norm': 0.3495531380176544, 'learning_rate': 4.200528973310892e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0096, 'grad_norm': 0.2877950668334961, 'learning_rate': 4.1003446341267935e-05, 'epoch': 0.36}\n",
      "{'loss': 0.0107, 'grad_norm': 0.5881220698356628, 'learning_rate': 4.0001602949426944e-05, 'epoch': 0.4}\n",
      "{'loss': 0.0071, 'grad_norm': 0.25795596837997437, 'learning_rate': 3.899975955758596e-05, 'epoch': 0.44}\n",
      "{'loss': 0.0079, 'grad_norm': 0.34749624133110046, 'learning_rate': 3.7997916165744976e-05, 'epoch': 0.48}\n",
      "{'loss': 0.0076, 'grad_norm': 0.26697781682014465, 'learning_rate': 3.6996072773903985e-05, 'epoch': 0.52}\n",
      "{'loss': 0.0061, 'grad_norm': 0.5447590947151184, 'learning_rate': 3.5994229382063e-05, 'epoch': 0.56}\n",
      "{'loss': 0.0053, 'grad_norm': 0.005761171691119671, 'learning_rate': 3.499238599022201e-05, 'epoch': 0.6}\n",
      "{'loss': 0.0057, 'grad_norm': 0.03233227878808975, 'learning_rate': 3.399054259838102e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0056, 'grad_norm': 0.1631012111902237, 'learning_rate': 3.2988699206540035e-05, 'epoch': 0.68}\n",
      "{'loss': 0.0055, 'grad_norm': 0.9342409372329712, 'learning_rate': 3.1986855814699044e-05, 'epoch': 0.72}\n",
      "{'loss': 0.0049, 'grad_norm': 0.37236925959587097, 'learning_rate': 3.098501242285806e-05, 'epoch': 0.76}\n",
      "{'loss': 0.0052, 'grad_norm': 0.06355077773332596, 'learning_rate': 2.9983169031017072e-05, 'epoch': 0.8}\n",
      "{'loss': 0.0044, 'grad_norm': 0.461061030626297, 'learning_rate': 2.8981325639176088e-05, 'epoch': 0.84}\n",
      "{'loss': 0.0044, 'grad_norm': 0.027873799204826355, 'learning_rate': 2.7979482247335097e-05, 'epoch': 0.88}\n",
      "{'loss': 0.0042, 'grad_norm': 0.01718631386756897, 'learning_rate': 2.697763885549411e-05, 'epoch': 0.92}\n",
      "{'loss': 0.0041, 'grad_norm': 0.1272663176059723, 'learning_rate': 2.5975795463653126e-05, 'epoch': 0.96}\n",
      "{'loss': 0.0038, 'grad_norm': 0.017637399956583977, 'learning_rate': 2.4973952071812135e-05, 'epoch': 1.0}\n",
      "{'loss': 0.0037, 'grad_norm': 0.005604166071861982, 'learning_rate': 2.3972108679971147e-05, 'epoch': 1.04}\n",
      "{'loss': 0.0037, 'grad_norm': 0.3547190725803375, 'learning_rate': 2.297026528813016e-05, 'epoch': 1.08}\n",
      "{'loss': 0.0037, 'grad_norm': 0.19474366307258606, 'learning_rate': 2.1968421896289172e-05, 'epoch': 1.12}\n",
      "{'loss': 0.0031, 'grad_norm': 0.010395209304988384, 'learning_rate': 2.0966578504448188e-05, 'epoch': 1.16}\n",
      "{'loss': 0.0033, 'grad_norm': 0.4928243160247803, 'learning_rate': 1.9964735112607197e-05, 'epoch': 1.2}\n",
      "{'loss': 0.0033, 'grad_norm': 0.43776535987854004, 'learning_rate': 1.896289172076621e-05, 'epoch': 1.24}\n",
      "{'loss': 0.0033, 'grad_norm': 0.0035234522074460983, 'learning_rate': 1.7961048328925222e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0035, 'grad_norm': 0.19154232740402222, 'learning_rate': 1.6959204937084235e-05, 'epoch': 1.32}\n",
      "{'loss': 0.0037, 'grad_norm': 0.029472067952156067, 'learning_rate': 1.595736154524325e-05, 'epoch': 1.36}\n",
      "{'loss': 0.0028, 'grad_norm': 0.07093489915132523, 'learning_rate': 1.4955518153402261e-05, 'epoch': 1.4}\n",
      "{'loss': 0.0025, 'grad_norm': 0.1912657916545868, 'learning_rate': 1.3953674761561272e-05, 'epoch': 1.44}\n",
      "{'loss': 0.0032, 'grad_norm': 0.002096298849210143, 'learning_rate': 1.2951831369720285e-05, 'epoch': 1.48}\n",
      "{'loss': 0.0023, 'grad_norm': 0.0016108975978568196, 'learning_rate': 1.1949987977879299e-05, 'epoch': 1.52}\n",
      "{'loss': 0.0027, 'grad_norm': 0.5881258845329285, 'learning_rate': 1.0948144586038311e-05, 'epoch': 1.56}\n",
      "{'loss': 0.0026, 'grad_norm': 0.19357255101203918, 'learning_rate': 9.946301194197324e-06, 'epoch': 1.6}\n",
      "{'loss': 0.0028, 'grad_norm': 0.24117736518383026, 'learning_rate': 8.944457802356336e-06, 'epoch': 1.64}\n",
      "{'loss': 0.0023, 'grad_norm': 0.0020652390085160732, 'learning_rate': 7.942614410515349e-06, 'epoch': 1.68}\n",
      "{'loss': 0.0024, 'grad_norm': 0.011984567157924175, 'learning_rate': 6.94077101867436e-06, 'epoch': 1.72}\n",
      "{'loss': 0.0022, 'grad_norm': 0.008332176133990288, 'learning_rate': 5.938927626833374e-06, 'epoch': 1.76}\n",
      "{'loss': 0.0026, 'grad_norm': 0.09290752559900284, 'learning_rate': 4.937084234992386e-06, 'epoch': 1.8}\n",
      "{'loss': 0.0024, 'grad_norm': 0.17205919325351715, 'learning_rate': 3.935240843151399e-06, 'epoch': 1.84}\n",
      "{'loss': 0.0024, 'grad_norm': 0.14588718116283417, 'learning_rate': 2.9333974513104112e-06, 'epoch': 1.88}\n",
      "{'loss': 0.0021, 'grad_norm': 0.0030445049051195383, 'learning_rate': 1.9315540594694237e-06, 'epoch': 1.92}\n",
      "{'loss': 0.0023, 'grad_norm': 0.05321648344397545, 'learning_rate': 9.297106676284363e-07, 'epoch': 1.96}\n",
      "{'train_runtime': 4357.5372, 'train_samples_per_second': 45.828, 'train_steps_per_second': 5.729, 'train_loss': 0.016849695425674598, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=24964, training_loss=0.016849695425674598, metrics={'train_runtime': 4357.5372, 'train_samples_per_second': 45.828, 'train_steps_per_second': 5.729, 'train_loss': 0.016849695425674598, 'epoch': 2.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Save the Fine-tuned Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\mokht\\\\Desktop\\\\CBRC_ED_Project\\\\saved_models\\\\t5_smiles_model\\\\tokenizer_config.json',\n",
       " 'C:\\\\Users\\\\mokht\\\\Desktop\\\\CBRC_ED_Project\\\\saved_models\\\\t5_smiles_model\\\\special_tokens_map.json',\n",
       " 'C:\\\\Users\\\\mokht\\\\Desktop\\\\CBRC_ED_Project\\\\saved_models\\\\t5_smiles_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path = r'C:\\Users\\mokht\\Desktop\\CBRC_ED_Project\\saved_models\\t5_smiles_model'\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Load Fine-tuned Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the fine-tuned model and tokenizer\n",
    "model_save_path = r'C:\\Users\\mokht\\Desktop\\CBRC_ED_Project\\saved_models\\t5_smiles_model'\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_save_path)\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_save_path)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Encoder Embeddings and Token Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String's Length: 34\n",
      "Number of tokens: 31\n",
      "Embedding: tensor([[[-0.0794, -0.0196, -0.1027,  ...,  0.1986, -0.0344,  0.1155],\n",
      "         [-0.2519, -0.1162, -0.0213,  ...,  0.0628,  0.0564,  0.0233],\n",
      "         [-0.0664,  0.0070, -0.0521,  ..., -0.1870,  0.1103,  0.0472],\n",
      "         ...,\n",
      "         [-0.1752,  0.0316, -0.0411,  ...,  0.1669, -0.0772,  0.0534],\n",
      "         [ 0.0467, -0.2008,  0.1495,  ...,  0.1188, -0.0050,  0.0150],\n",
      "         [-0.2719,  0.0716,  0.0740,  ..., -0.3742,  0.2752, -0.1003]]],\n",
      "       device='cuda:0')\n",
      "Embedding's Shape: torch.Size([1, 31, 512])\n"
     ]
    }
   ],
   "source": [
    "def get_encoder_embeddings_and_count_tokens(model, tokenizer, smiles):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(smiles, return_tensors=\"pt\", padding=True, truncation=True, max_length=110)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    token_count = inputs['input_ids'].shape[1]\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs = model.encoder(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "    return encoder_outputs.last_hidden_state, token_count\n",
    "\n",
    "smiles_string = \"O=Cc1ccc2occ(-c3nnn[nH]3)c(=O)c2c1\"\n",
    "embeddings, token_count = get_encoder_embeddings_and_count_tokens(model, tokenizer, smiles_string)\n",
    "print(f\"String's Length: {len(smiles_string)}\")\n",
    "print(f\"Number of tokens: {token_count}\")\n",
    "print(f\"Embedding: {embeddings}\")\n",
    "print(f\"Embedding's Shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 SMILES Encoding and Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: O=Cc1ccc2occ(-c3nnn[nH]3)c(=O)c2c1, Reconstructed: O=Cc1ccc2occ(-c3nnn[nH]3)c(=O)c2c1\n"
     ]
    }
   ],
   "source": [
    "def encode_decode_smiles(model, tokenizer, smiles, max_length=110):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(smiles, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            input_ids=inputs['input_ids'],\n",
    "            attention_mask=inputs['attention_mask'],\n",
    "            max_length=max_length,\n",
    "            num_beams=5,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    decoded_smiles = \"\".join(tokenizer.convert_ids_to_tokens(generated_ids[0], skip_special_tokens=True))\n",
    "    return decoded_smiles\n",
    "\n",
    "smiles_string = \"O=Cc1ccc2occ(-c3nnn[nH]3)c(=O)c2c1\"\n",
    "reconstructed_smiles = encode_decode_smiles(model, tokenizer, smiles_string, max_length=110)\n",
    "print(f\"Original: {smiles_string}, Reconstructed: {reconstructed_smiles}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Load and Preprocess Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:23:11] Explicit valence for atom # 6 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: Cc1nc(sc1)\\[NH]=C(\\N)N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:23:12] Explicit valence for atom # 5 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: c1(cc(N\\C(=[NH]\\c2cccc(c2)CC)C)ccc1)CC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:23:15] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:23:16] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:23:19] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:23:23] Explicit valence for atom # 1 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: O=N([O-])C1=C(CN=C1NCCSCc2ncccc2)Cc3ccccc3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:23:24] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:23:36] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:23:44] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:23:48] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:23:51] Explicit valence for atom # 5 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)N\\C(NC)=[NH]\\C#N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:23:57] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:23:58] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:24:04] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:24:14] Explicit valence for atom # 5 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)NC(C)=O\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:24:30] Explicit valence for atom # 11 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: s1cc(CSCCN\\C(NC)=[NH]\\C#N)nc1\\[NH]=C(\\N)N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:24:45] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:24:56] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:24:58] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:25:05] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:25:11] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:25:29] Explicit valence for atom # 6 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: c1(nc(NC(N)=[NH2])sc1)CSCCNC(=[NH]C#N)NC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:25:32] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[11:25:32] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: n1c(csc1\\[NH]=C(\\N)N)c1ccccc1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:25:33] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:25:42] Explicit valence for atom # 5 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:25:58] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:26:08] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:26:08] Explicit valence for atom # 12 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: c1c(c(ncc1)CSCCN\\C(=[NH]\\C#N)NCC)Br\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:26:12] WARNING: not removing hydrogen atom without neighbors\n",
      "[11:26:37] Explicit valence for atom # 5 N, 4, is greater than permitted\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to parse SMILES: s1cc(nc1\\[NH]=C(\\N)N)C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11:27:00] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after preprocessing: (499593, 1)\n",
      "Maximum SMILES length in dataset: 100\n",
      "SMILES strings with the maximum length:\n",
      "74862     CC1(C)C[C@@H]2C3=CC[C@@H]4[C@]5(C)CC[C@H](O)C(...\n",
      "351945    CC1(C)[C@@H](O)CC[C@@]2(C)[C@H]3CC=C4[C@@H]5C[...\n",
      "Name: SMILES, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cn1c(SCc2noc(-c3ccsc3)n2)nnc1C1CCS(=O)(=O)C1</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C=C1CCC2C(C)(CO)C(O)CCC2(C)C1CC(OC(=O)CC)C1=CC...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brc1ccc(-c2cn3nc(Cc4noc5ccccc45)sc3n2)cc1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCOC(=O)CC(=O)CSc1nc(-c2ccccc2)cc(-c2ccc(Cl)cc...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCCCCCOC(=O)[C@]12O[C@@]1(C/C(CO)=C(\\C)CC1(c3c...</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              SMILES  length\n",
       "0       Cn1c(SCc2noc(-c3ccsc3)n2)nnc1C1CCS(=O)(=O)C1      44\n",
       "1  C=C1CCC2C(C)(CO)C(O)CCC2(C)C1CC(OC(=O)CC)C1=CC...      51\n",
       "2          Brc1ccc(-c2cn3nc(Cc4noc5ccccc45)sc3n2)cc1      41\n",
       "3  CCOC(=O)CC(=O)CSc1nc(-c2ccccc2)cc(-c2ccc(Cl)cc...      53\n",
       "4  CCCCCCOC(=O)[C@]12O[C@@]1(C/C(CO)=C(\\C)CC1(c3c...      79"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_vae_test = r'C:\\Users\\mokht\\Desktop\\CBRC_ED_Project\\data\\composed_dataset_500k.csv'\n",
    "df_vae_test = pd.read_csv(file_path_vae_test, names=['SMILES'])\n",
    "df_vae_test['SMILES'] = df_vae_test['SMILES'].apply(canonicalize_smiles)\n",
    "df_vae_test.dropna(subset=['SMILES'], inplace=True)\n",
    "df_vae_test.drop_duplicates(subset=['SMILES'], inplace=True)\n",
    "print(\"Dataset shape after preprocessing:\", df_vae_test.shape)\n",
    "\n",
    "df_vae_test['length'] = df_vae_test['SMILES'].apply(len)\n",
    "max_length = df_vae_test['length'].max()\n",
    "longest_smiles = df_vae_test[df_vae_test['length'] == max_length]\n",
    "print(\"Maximum SMILES length in dataset:\", max_length)\n",
    "print(\"SMILES strings with the maximum length:\")\n",
    "print(longest_smiles['SMILES'])\n",
    "df_vae_test.head()\n",
    "\n",
    "preprocessed_file_path = r'C:\\Users\\mokht\\Desktop\\CBRC_ED_Project\\data\\preprocessed_composed_dataset_500k.csv'\n",
    "df_vae_test.to_csv(preprocessed_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Reload Preprocessed Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cn1c(SCc2noc(-c3ccsc3)n2)nnc1C1CCS(=O)(=O)C1</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C=C1CCC2C(C)(CO)C(O)CCC2(C)C1CC(OC(=O)CC)C1=CC...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brc1ccc(-c2cn3nc(Cc4noc5ccccc45)sc3n2)cc1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCOC(=O)CC(=O)CSc1nc(-c2ccccc2)cc(-c2ccc(Cl)cc...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCCCCCOC(=O)[C@]12O[C@@]1(C/C(CO)=C(\\C)CC1(c3c...</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              SMILES  length\n",
       "0       Cn1c(SCc2noc(-c3ccsc3)n2)nnc1C1CCS(=O)(=O)C1      44\n",
       "1  C=C1CCC2C(C)(CO)C(O)CCC2(C)C1CC(OC(=O)CC)C1=CC...      51\n",
       "2          Brc1ccc(-c2cn3nc(Cc4noc5ccccc45)sc3n2)cc1      41\n",
       "3  CCOC(=O)CC(=O)CSc1nc(-c2ccccc2)cc(-c2ccc(Cl)cc...      53\n",
       "4  CCCCCCOC(=O)[C@]12O[C@@]1(C/C(CO)=C(\\C)CC1(c3c...      79"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_file_path = r'C:\\Users\\mokht\\Desktop\\CBRC_ED_Project\\data\\preprocessed_composed_dataset_500k.csv'\n",
    "df_vae_test = pd.read_csv(preprocessed_file_path)\n",
    "df_vae_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Evaluate Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 500/500 [14:42<00:00,  1.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Accuracy: 0.994\n",
      "Mismatched SMILES strings:\n",
      "Original     : CCCCCCCC/C=C\\CCCCCCCCCCCCCC(=O)OC[C@H](COC(=O)CCCCCCCCCCCCCC)OCCCCCCCCCCCCCCCCCC\n",
      "Reconstructed: CCCCCCCC/C=C\\CCCCCCCCCCCCCC(=O)OC[C@H](COC(=O)CCCCCCCCCCCCCC)OCCCCCCCCCCCCCCCCCCC\n",
      "Original     : CCCCCCCCCCCCCC[C@H]1O[C@H]1CC/C=C\\CCCCCCCCCCC1=C[C@@H](C)OC1=O\n",
      "Reconstructed: CCCCCCCCCCCCCCC[C@H]1O[C@H]1CC/C=C\\CCCCCCCCCCC1=C[C@@H](C)OC1=O\n",
      "Original     : CC(C)=CCC/C(C)=C/C=C/C(C)=C/C=C/C(C)=C/C=C/C=C(C)/C=C/C=C(C)/C=C/C=C(\\C)CCC=C(C)C\n",
      "Reconstructed: CC(C)=CCC/C(C)=C/C=C/C(C)=C/C=C/C(C)=C/C=C/C=C(C)/C=C/C=C(C)/C=C/C=C(C)/C=C/C=C(\\C)CCC=C(C)C\n",
      "Average Levenshtein Distance: 0.026\n",
      "Validity of Generated SMILES: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Tanimoto Similarity: 100%|| 500/500 [00:00<00:00, 1221.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Tanimoto Similarity: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "sampled_df = df_vae_test.sample(n=500, random_state=42)\n",
    "sampled_smiles_list = sampled_df['SMILES'].tolist()\n",
    "\n",
    "def exact_match_accuracy(original_smiles_list, reconstructed_smiles_list):\n",
    "    correct = 0\n",
    "    mismatches = []\n",
    "    for orig, recon in zip(original_smiles_list, reconstructed_smiles_list):\n",
    "        if orig == recon:\n",
    "            correct += 1\n",
    "        else:\n",
    "            mismatches.append((orig, recon))\n",
    "    total = len(original_smiles_list)\n",
    "    accuracy = correct / total\n",
    "    return accuracy, mismatches\n",
    "\n",
    "def average_levenshtein_distance(original_smiles_list, reconstructed_smiles_list):\n",
    "    total_distance = sum([Levenshtein.distance(orig, recon) for orig, recon in zip(original_smiles_list, reconstructed_smiles_list)])\n",
    "    total = len(original_smiles_list)\n",
    "    return total_distance / total\n",
    "\n",
    "def validity_of_generated_smiles(reconstructed_smiles_list):\n",
    "    valid_count = sum([1 for s in reconstructed_smiles_list if Chem.MolFromSmiles(s) is not None])\n",
    "    total = len(reconstructed_smiles_list)\n",
    "    return valid_count / total\n",
    "\n",
    "def average_tanimoto_similarity(original_smiles_list, reconstructed_smiles_list):\n",
    "    similarities = []\n",
    "    morgan_gen = GetMorganGenerator(radius=2, fpSize=2048)\n",
    "    for orig, recon in tqdm(zip(original_smiles_list, reconstructed_smiles_list), total=len(original_smiles_list), desc=\"Calculating Tanimoto Similarity\"):\n",
    "        mol_orig = Chem.MolFromSmiles(orig)\n",
    "        mol_recon = Chem.MolFromSmiles(recon)\n",
    "        if mol_orig and mol_recon:\n",
    "            fp_orig = morgan_gen.GetFingerprint(mol_orig)\n",
    "            fp_recon = morgan_gen.GetFingerprint(mol_recon)\n",
    "            similarity = DataStructs.TanimotoSimilarity(fp_orig, fp_recon)\n",
    "            similarities.append(similarity)\n",
    "    return sum(similarities) / len(similarities)\n",
    "\n",
    "original_smiles_list = sampled_smiles_list\n",
    "reconstructed_smiles_list = []\n",
    "\n",
    "for s in tqdm(original_smiles_list, desc=\"Evaluating\"):\n",
    "    reconstructed_smiles_list.append(encode_decode_smiles(model, tokenizer, s, max_length=110))\n",
    "\n",
    "accuracy, mismatches = exact_match_accuracy(original_smiles_list, reconstructed_smiles_list)\n",
    "print(f\"Exact Match Accuracy: {accuracy}\")\n",
    "\n",
    "print(\"Mismatched SMILES strings:\")\n",
    "for orig, recon in mismatches[:10]:\n",
    "    print(f\"Original     : {orig}\")\n",
    "    print(f\"Reconstructed: {recon}\")\n",
    "\n",
    "average_distance = average_levenshtein_distance(original_smiles_list, reconstructed_smiles_list)\n",
    "print(f\"Average Levenshtein Distance: {average_distance}\")\n",
    "\n",
    "validity = validity_of_generated_smiles(reconstructed_smiles_list)\n",
    "print(f\"Validity of Generated SMILES: {validity}\")\n",
    "\n",
    "average_similarity = average_tanimoto_similarity(original_smiles_list, reconstructed_smiles_list)\n",
    "print(f\"Average Tanimoto Similarity: {average_similarity}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
